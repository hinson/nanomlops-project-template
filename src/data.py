import subprocess
from pathlib import Path

import pandas as pd
from prefect import task
from sklearn.datasets import make_classification

# å®šä¹‰æ•°æ®å­˜æ”¾çš„ç›¸å¯¹è·¯å¾„
DATA_DIR = Path("data")
RAW_DATA_PATH = DATA_DIR / "raw_dataset.csv"


@task(name="Pull Data from DVC")
def pull_data_from_dvc() -> None:
    """
    è°ƒç”¨ DVC å‘½ä»¤è¡Œæ‹‰å–æœ€æ–°æ•°æ®ã€‚

    è¿™ç¡®ä¿äº†åœ¨è®­ç»ƒå¼€å§‹å‰ï¼Œæœ¬åœ°æ‹¥æœ‰ä¸ .dvc.lock ä¸­è®°å½•ä¸€è‡´çš„æ•°æ®ç‰ˆæœ¬ã€‚
    å¦‚æœ DVC æœªé…ç½®æˆ–è¿œç¨‹è¿æ¥å¤±è´¥ï¼Œå°†æŠ›å‡ºå¼‚å¸¸ã€‚
    """
    print("Attempting to pull data from DVC remote...")

    # æ£€æŸ¥å½“å‰ç›®å½•ä¸‹æ˜¯å¦æœ‰ .dvc ç›®å½•ï¼Œåˆ¤æ–­æ˜¯å¦ä¸º DVC é¡¹ç›®
    if not Path(".dvc").exists():
        print("Warning: Not a DVC repository. Skipping dvc pull.")
        return

    try:
        # ä½¿ç”¨ subprocess è°ƒç”¨ dvc pull
        # capture_output=True ç”¨äºæ•è·æ ‡å‡†è¾“å‡ºï¼Œé¿å…åœ¨æ—¥å¿—ä¸­åˆ·å±ï¼Œé™¤éå‡ºé”™
        subprocess.run(["dvc", "pull"], check=True, capture_output=True, text=True)
        print("âœ… DVC pull completed successfully.")
    except subprocess.CalledProcessError as e:
        # å¦‚æœæ˜¯å› ä¸ºæ²¡æœ‰é…ç½® remote æˆ–è€…æ˜¯ç¦»çº¿çŠ¶æ€ï¼Œæ‰“å°è­¦å‘Šè€Œä¸æ˜¯ç›´æ¥å´©æºƒ
        print(f"âš ï¸ Warning: DVC pull failed. Error: {e.stderr}")
        print("Proceeding with local files if available...")


@task(name="Load Raw Data")
def load_raw_data(file_path: Path = RAW_DATA_PATH) -> pd.DataFrame:
    """
    åŠ è½½åŸå§‹ CSV æ•°æ®ã€‚

    å¦‚æœæŒ‡å®šè·¯å¾„çš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤ºç›®çš„ã€‚
    è¿™ä½¿å¾—é¡¹ç›®æ¨¡ç‰ˆå¯ä»¥åœ¨æ²¡æœ‰ä»»ä½•å¤–éƒ¨æ•°æ®ä¾èµ–çš„æƒ…å†µä¸‹ç›´æ¥è¿è¡Œã€‚
    """
    if not file_path.exists():
        print(f"âš ï¸ Data file {file_path} not found.")
        print("ğŸ”„ Generating dummy data for demonstration...")

        # ç”Ÿæˆæ¨¡æ‹Ÿåˆ†ç±»æ•°æ®
        X, y = make_classification(
            n_samples=1000,
            n_features=10,
            n_informative=5,
            n_redundant=2,
            random_state=42,
        )

        df = pd.DataFrame(X, columns=[f"feature_{i}" for i in range(10)])
        df["target"] = y

        # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
        file_path.parent.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜æ¨¡æ‹Ÿæ•°æ®ï¼Œè¿™æ ·ä¸‹æ¬¡è¿è¡Œæ—¶å°±ä¼šç›´æ¥åŠ è½½è¿™ä¸ªæ–‡ä»¶
        df.to_csv(file_path, index=False)
        print(f"âœ… Dummy data saved to {file_path}")
        return df

    print(f"ğŸ“‚ Loading data from {file_path}...")
    df = pd.read_csv(file_path)
    print(f"âœ… Data loaded. Shape: {df.shape}")
    return df


@task(name="Preprocess Data")
def preprocess_data(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:
    """
    æ‰§è¡Œæ•°æ®é¢„å¤„ç†å’Œç‰¹å¾ç›®æ ‡åˆ†ç¦»ã€‚

    Steps:
    1. å¡«å……ç¼ºå¤±å€¼ (æ­¤å¤„ç®€å•å¡«å……ä¸º 0)
    2. åˆ†ç¦»ç‰¹å¾ (X) å’Œ ç›®æ ‡å˜é‡ (y)
    """
    # 1. ç®€å•çš„æ¸…æ´—é€»è¾‘
    if df.isnull().values.any():
        print("Found missing values, filling with 0...")
        df = df.fillna(0)

    # 2. è¯†åˆ«ç›®æ ‡åˆ—
    # å‡è®¾ 'target' åˆ—å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å–æœ€åä¸€åˆ—
    target_col = "target"
    if target_col not in df.columns:
        target_col = df.columns[-1]
        print(f"Column 'target' not found, using last column '{target_col}' as target.")

    X = df.drop(columns=[target_col])
    y = df[target_col]

    print(f"âœ… Preprocessing done. Features: {X.shape}, Target: {y.shape}")
    return X, y
